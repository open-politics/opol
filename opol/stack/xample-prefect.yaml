name: opol-flows
prefect-version: 3.10.0


## This is pretty much what our production prefect.yaml looks like. 
## The only difference is that in production we use a different infra (kubernetes)
## In our actual deployment the pool is thus "kubernetes-pool-prod"
## Generally, for your understanding on prefect: it doesn't actually matter where that pool is. The worker just provisions the containers specified here.
## BUT in our setup this is not 1:1 possible. We are not fully decoupled in that containers still need to reach other conrtainers and that data is passed via redisu queues.
## So for opol we can't choose ANY infra. We can choose infra that the rest of our stack is depoyed on and where containers can call each other by name.
## To correctly target the correct ports the core/service_mapping builds dynamic urls to reach the services. 
## In the python-client/main we have a similar hack to call the correct url (e.g. on docker: host + port while on kubernetes it's just host)

pull: 
  - prefect.deployments.steps.git_clone:
      repository: https://github.com/open-politics/opol.git
      credentials: "{{ prefect.blocks.github-credentials.YOUR_GITHUB_CREDS }}"
  - prefect.deployments.steps.set_working_directory:
      directory: /app/opol/opol/stack/

deployments:

  - name: meta
    entrypoint: ./flows/orchestration/orchestration.py:meta_flow
    work_pool:
      name: docker-pool
      job_variables:
        image: openpoliticsproject/worker-base:latest
        env:
          LOGFIRE_TOKEN: "YOUR_LOGFIRE_TOKEN"
          REDIS_PORT: "YOUR_REDIS_PORT"
          REDIS_URL: "YOUR_REDIS_URL"
          GOOGLE_API_KEY: "YOUR_GOOGLE_API_KEY"
          OPOL_API_KEY: "YOUR_OPOL_API_KEY"
          OPOL_MODE: "container"
        networks:
          - opol-app-stack
    version: "1.0.0"
    tags: ["core-processing-flows"]
    description: The main flow to orchestrate all flows.
    enforce_parameter_schema: true
    schedules:
      - cron: "*/5 * * * *" # Run every 5 minutes

  - name: scraping
    entrypoint: ./flows/scraping/scrape_newssites.py:scrape_newssites_flow
    parameters:
      flags: ["cnn", "dw", "bbc"]
    work_pool:
      name: docker-pool
      job_variables:
        image: openpoliticsproject/flow-scraping:latest
        env:
          LOGFIRE_TOKEN: "YOUR_LOGFIRE_TOKEN"
          REDIS_PORT: "YOUR_REDIS_PORT"
          REDIS_URL: "YOUR_REDIS_URL"
          GOOGLE_API_KEY: "YOUR_GOOGLE_API_KEY"
          OPOL_API_KEY: "YOUR_OPOL_API_KEY"
          OPOL_MODE: "container"
        networks:
          - opol-app-stack
    version: "1.0.0"
    tags: ["core-processing-flows"]
    description: The main flow to scrape newssites.
    enforce_parameter_schema: true
    schedules:
      - cron: "*/30 * * * *" # Run every 30 minutes

  - name: entities
    entrypoint: ./flows/entities/extract_entities.py:extract_entities_flow
    work_pool:
      name: docker-pool
      job_variables:
        image: openpoliticsproject/flow-entities:latest
        env:
          LOGFIRE_TOKEN: "YOUR_LOGFIRE_TOKEN"
          REDIS_PORT: "YOUR_REDIS_PORT"
          REDIS_URL: "YOUR_REDIS_URL"
          PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: "python"
        networks:
          - opol-app-stack
    version: "1.0.0"
    tags: ["core-processing-flows"]
    description: The main flow to extract entities.
    enforce_parameter_schema: true
    schedules:
      - cron: "0 * * * *" # Run every hour

  - name: geocoding
    entrypoint: ./flows/geocoding/geocode_locations.py:geocode_locations_flow
    parameters:
      batch_size: 200
    work_pool:
      name: docker-pool
      job_variables:
        image: openpoliticsproject/worker-base:latest
        env:
          LOGFIRE_TOKEN: "YOUR_LOGFIRE_TOKEN"
          REDIS_PORT: "YOUR_REDIS_PORT"
          REDIS_URL: "YOUR_REDIS_URL"
        networks:
          - opol-app-stack
    version: "1.0.0"
    tags: ["core-processing-flows"]
    description: The main flow to geocode locations.
    enforce_parameter_schema: true
    schedules:
      - cron: "0 * * * *" # Run every hour

  - name: classification
    entrypoint: ./flows/classification/classification_flow.py:classify_contents_flow
    parameters:
      batch_size: 20
    work_pool:
      name: docker-pool
      job_variables:
        image: openpoliticsproject/worker-base:latest
        env:
          LOGFIRE_TOKEN: "YOUR_LOGFIRE_TOKEN"
          REDIS_PORT: "YOUR_REDIS_PORT"
          REDIS_URL: "YOUR_REDIS_URL"
          GOOGLE_API_KEY: "YOUR_GOOGLE_API_KEY"
          OPOL_API_KEY: "YOUR_OPOL_API_KEY"
          OPOL_MODE: "container"
        networks:
          - opol-app-stack
    version: "1.0.0"
    tags: ["core-processing-flows"]
    description: The main flow to classify contents.
    enforce_parameter_schema: true
    schedules:
      - cron: "0 * * * *" # Run every hour
